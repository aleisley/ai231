{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82811892",
   "metadata": {},
   "source": [
    "### ME2: AlexNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65963a",
   "metadata": {},
   "source": [
    "#### Import necessary packages\n",
    "\n",
    "This notebook demonstrates custom deep learning inference using NumPy for portability and clarity.\n",
    "\n",
    "- **NumPy** is the core array library we use to implement convolution, pooling, activation, and linear layers from scratch.\n",
    "- We still rely on PyTorch / torchvision for data loading and to access pretrained AlexNet weights.\n",
    "- Supporting packages (einops for concise tensor algebra, tqdm for progress reporting) round out the tooling.\n",
    "\n",
    "The imports below are grouped to highlight standard libraries, third-party utilities, and NumPy stride tricks used for patch extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb363a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from functools import wraps\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "# Third-party imports\n",
    "from einops import einsum\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision.models import AlexNet_Weights\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# NumPy imports\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526892a",
   "metadata": {},
   "source": [
    "#### Load the weights and biases of AlexNet\n",
    "\n",
    "In this section, we extract the pretrained weights and biases from torchvision's AlexNet model.\n",
    "\n",
    "- The weights and biases are loaded using the default configuration from `AlexNet_Weights`.\n",
    "- These parameters are stored in a dictionary and printed to verify the available keys.\n",
    "- Our custom layers will use these pretrained values for inference, ensuring the model matches the original AlexNet architecture.\n",
    "\n",
    "This step is essential for initializing all custom layers with correct parameters before running inference on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ee8f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = AlexNet_Weights.DEFAULT.get_state_dict()\n",
    "print(weights_and_biases.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635ee35",
   "metadata": {},
   "source": [
    "#### Custom Modules and Mixins\n",
    "\n",
    "We replace `torch.nn.Module`/`nn.Sequential` with lightweight NumPy-native\n",
    "wrappers so the rest of the notebook can stay framework-free once the\n",
    "weights are loaded. `NumpyModule` keeps the familiar \"forward/\n",
    "**call**/train/eval\" surface, while `NumpySequential` chains layers just\n",
    "like PyTorch's container.\n",
    "\n",
    "The same section also defines mixins used by later layers:\n",
    "\n",
    "- `WeightsAndBiasMixin` pulls pretrained tensors from the AlexNet state dict\n",
    "  and converts them to NumPy.\n",
    "- `PatchMixin` provides the shared sliding-window extraction that powers\n",
    "  both convolution and pooling implementations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2dfa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyModule:\n",
    "    \"\"\"Minimal module interface for NumPy-based layers.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.training = True\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        self.training = mode\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        return self.train(False)\n",
    "\n",
    "\n",
    "class NumpySequential(NumpyModule):\n",
    "    \"\"\"Sequential container chaining NumpyModule layers.\"\"\"\n",
    "\n",
    "    def __init__(self, *layers):\n",
    "        super().__init__()\n",
    "        self.layers = list(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        super().train(mode)\n",
    "        for layer in self.layers:\n",
    "            train_fn = getattr(layer, 'train', None)\n",
    "            if callable(train_fn):\n",
    "                train_fn(mode)\n",
    "        return self\n",
    "\n",
    "\n",
    "class PatchMixin:\n",
    "    \"\"\"Mixin for extracting patches from input arrays with a given kernel size and stride.\n",
    "    Used for convolution and pooling operations on NumPy arrays.\"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: int, stride: int) -> None:\n",
    "        \"\"\"Initialize patch extraction parameters.\n",
    "        Args:\n",
    "            kernel_size (int): Size of the square kernel.\n",
    "            stride (int): Stride for patch extraction.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def _patch_with_stride(self, x_pad: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Extract k x k patches from the input array with the given stride.\n",
    "        Args:\n",
    "            x_pad (np.ndarray): Input array of shape (b, c, h, w).\n",
    "        Returns:\n",
    "            np.ndarray: Array of shape (b, c, h/stride, w/stride, k, k) containing the extracted patches.\n",
    "        \"\"\"\n",
    "        windows = sliding_window_view(  # type: ignore\n",
    "            x_pad,\n",
    "            window_shape=(self.kernel_size, self.kernel_size),\n",
    "            axis=(-2, -1)  # type: ignore\n",
    "        )\n",
    "        return windows[:, :, ::self.stride, ::self.stride, :, :]\n",
    "\n",
    "\n",
    "class WeightsAndBiasMixin:\n",
    "    \"\"\"Mixin for loading pretrained weights and biases from a state dict as NumPy arrays.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        \"\"\"Initialize the mixin (calls super).\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def init_weights_and_bias(self, weight_loc: str, bias_loc: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Load weights and biases from the state dict.\n",
    "        Args:\n",
    "            weight_loc (str): Key for weights in the state dict.\n",
    "            bias_loc (str): Key for biases in the state dict.\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: NumPy arrays for weights and biases.\n",
    "        \"\"\"\n",
    "        weight = weights_and_biases[weight_loc].detach().cpu().numpy()\n",
    "        bias = weights_and_biases[bias_loc].detach().cpu().numpy()\n",
    "        return weight, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ebd56",
   "metadata": {},
   "source": [
    "#### Profiling Usage\n",
    "\n",
    "All forward methods are wrapped with a lightweight timing decorator storing per-call events in `PROFILE_EVENTS`.\n",
    "\n",
    "After running inference you can view an aggregate table:\n",
    "\n",
    "```python\n",
    "profile_summary()                 # default sort by total time\n",
    "profile_summary(sort=\"mean\")      # sort by mean per call\n",
    "profile_summary(sort=\"max\")       # highlight worst single call\n",
    "profile_summary(top_n=5)          # show only top 5 layers\n",
    "```\n",
    "\n",
    "Columns:\n",
    "\n",
    "- Total(ms): cumulative time across calls\n",
    "- Mean(ms): average per invocation\n",
    "- Max(ms): slowest single invocation\n",
    "- Calls: number of times that layer's forward executed\n",
    "\n",
    "To reset profiling data between experiments:\n",
    "\n",
    "```python\n",
    "PROFILE_EVENTS.clear()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93abbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling utilities: decorator to time forward methods\n",
    "PROFILE_EVENTS = []  # list of dicts: {\"name\": str, \"elapsed\": float}\n",
    "\n",
    "\n",
    "def profile_forward(name: str | None = None):\n",
    "    \"\"\"Decorator to measure execution time of forward methods.\n",
    "\n",
    "    Args:\n",
    "        name: Optional override name. If None attempts to derive from self.__class__.__name__.\n",
    "    \"\"\"\n",
    "    def outer(fn):\n",
    "        @wraps(fn)\n",
    "        def inner(self, *args, **kwargs):\n",
    "            label = name or self.__class__.__name__\n",
    "            start = time.perf_counter()\n",
    "            out = fn(self, *args, **kwargs)\n",
    "            end = time.perf_counter()\n",
    "            PROFILE_EVENTS.append({\"name\": label, \"elapsed\": end - start})\n",
    "            return out\n",
    "        return inner\n",
    "    return outer\n",
    "\n",
    "\n",
    "def profile_summary(sort: str = \"total\", top_n: int | None = None):\n",
    "    \"\"\"Print aggregated profiling results.\n",
    "\n",
    "    Args:\n",
    "        sort: One of {\"total\", \"mean\", \"calls\", \"max\"} to control ordering.\n",
    "        top_n: If provided, limit output rows.\n",
    "    \"\"\"\n",
    "    if not PROFILE_EVENTS:\n",
    "        print(\"No profiling data collected.\")\n",
    "        return\n",
    "    agg = defaultdict(lambda: {\"total\": 0.0, \"calls\": 0, \"max\": 0.0})\n",
    "    for ev in PROFILE_EVENTS:\n",
    "        a = agg[ev[\"name\"]]\n",
    "        a[\"total\"] += ev[\"elapsed\"]\n",
    "        a[\"calls\"] += 1\n",
    "        if ev[\"elapsed\"] > a[\"max\"]:\n",
    "            a[\"max\"] = ev[\"elapsed\"]\n",
    "    rows = []\n",
    "    for name, stats in agg.items():\n",
    "        mean = stats[\"total\"] / stats[\"calls\"]\n",
    "        rows.append({\"name\": name, **stats, \"mean\": mean})\n",
    "    rows.sort(key=lambda r: r[sort], reverse=True)\n",
    "    if top_n is not None:\n",
    "        rows = rows[:top_n]\n",
    "    header = f\"{'Layer':<22} {'Calls':>5} {'Total(ms)':>12} {'Mean(ms)':>12} {'Max(ms)':>12}\"\n",
    "    print(header)\n",
    "    print('-' * len(header))\n",
    "    for r in rows:\n",
    "        print(f\"{r['name']:<22} {r['calls']:>5} {r['total']*1000:>12.3f} {r['mean']*1000:>12.3f} {r['max']*1000:>12.3f}\")\n",
    "    total_time = sum(r['total'] for r in rows)\n",
    "    print('-' * len(header))\n",
    "    print(\n",
    "        f\"Total profiled time: {total_time*1000:.2f} ms across {len(PROFILE_EVENTS)} calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5429bfd",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "In this section, we load the ImageNet validation dataset and prepare it for inference with our custom NumPy-based AlexNet implementation.\n",
    "\n",
    "- We use torchvision's `ImageNet` class to access the validation split, applying the standard AlexNet preprocessing transforms.\n",
    "- The DataLoader batches images; our custom `default_collate` converts tensors directly to NumPy arrays.\n",
    "- Keeping everything in NumPy simplifies the educational focus (no device transfers or GPU specifics).\n",
    "\n",
    "This setup enables end-to-end inference using only NumPy for tensor operations alongside pretrained weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8698e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_root() -> Path:\n",
    "    \"\"\" Return a dataset root path, preferring Google Drive if on Colab \"\"\"\n",
    "\n",
    "    COLAB_DRIVE_ROOT = Path(\"/content/drive/MyDrive/datasets/ImageNet1k\")\n",
    "    DEFAULT_LOCAL_ROOT = Path(\"data/ImageNet1k\")\n",
    "\n",
    "    try:\n",
    "        import google.colab  # type: ignore\n",
    "    except ImportError:\n",
    "        return DEFAULT_LOCAL_ROOT\n",
    "\n",
    "    try:\n",
    "        from google.colab import drive  # type: ignore\n",
    "        drive.mount(\"/content/drive\")\n",
    "        return COLAB_DRIVE_ROOT\n",
    "    except Exception as e:\n",
    "        print(f'[WARNING] Could not mound Google Drive {e}')\n",
    "        return DEFAULT_LOCAL_ROOT\n",
    "\n",
    "\n",
    "def default_collate(batch):\n",
    "    \"\"\"\n",
    "    Collate function converting incoming PyTorch tensors to NumPy arrays.\n",
    "\n",
    "    We convert tensors early so all subsequent custom layers operate purely on\n",
    "    NumPy arrays (no device transfers needed).\n",
    "    \"\"\"\n",
    "    imgs, labels = zip(*batch)  # imgs: tuple[torch.Tensor], labels: tuple[int]\n",
    "    imgs = [np.asarray(img.numpy(), dtype=np.float32) for img in imgs]\n",
    "    imgs = np.stack(imgs, axis=0)                 # [B,3,224,224]\n",
    "    labels = np.asarray(labels, dtype=np.int64)    # [B]\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "imagenet_val = ImageNet(\n",
    "    root=get_data_root(),\n",
    "    split=\"val\",\n",
    "    transform=AlexNet_Weights.IMAGENET1K_V1.transforms()\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    imagenet_val,\n",
    "    batch_size=256,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=default_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11075a2b",
   "metadata": {},
   "source": [
    "#### Define the custom Conv2d\n",
    "\n",
    "We implement convolution with an explicit im2col + GEMM strategy:\n",
    "\n",
    "1. (Optional) pad the input.\n",
    "2. Use `sliding_window_view` to obtain a strided view of all kÃ—k receptive fields.\n",
    "3. Reshape (B, C, out_h, out_w, k, k) -> (B*out_h*out_w, C*k*k).\n",
    "4. Reshape weights (C_out, C, k, k) -> (C_out, C*k*k).\n",
    "5. Perform a single matrix multiply and reshape back.\n",
    "\n",
    "Compared to a high-rank `einsum` over the patch tensor, this form usually maps better onto optimized BLAS routines, improving runtime for large kernels and early layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552c4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConv2d(WeightsAndBiasMixin, PatchMixin, NumpyModule):\n",
    "    \"\"\"\n",
    "    Custom 2D Convolution layer using NumPy and an im2col + GEMM strategy.\n",
    "\n",
    "    Steps:\n",
    "      1. (Optional) Pad input.\n",
    "      2. Extract sliding windows (im2col) with stride via `sliding_window_view`.\n",
    "      3. Reshape patches to a 2D matrix (B*out_h*out_w, C*k*k).\n",
    "      4. Reshape weights to (out_channels, C*k*k) and perform a matrix multiply.\n",
    "      5. Reshape back to (B, out_channels, out_h, out_w) and add bias.\n",
    "\n",
    "    This avoids a high-rank einsum over strided memory and leverages optimized BLAS.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        stride: int = 1,\n",
    "        padding: int = 0,\n",
    "        weight_loc: str = '',\n",
    "        bias_loc: str = '',\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the convolution layer with parameters and pretrained weights/biases.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int): Size of the convolution kernel.\n",
    "            stride (int, optional): Stride for convolution. Defaults to 1.\n",
    "            padding (int, optional): Padding for input. Defaults to 0.\n",
    "            weight_loc (str, optional): Key for weights in state dict.\n",
    "            bias_loc (str, optional): Key for biases in state dict.\n",
    "        \"\"\"\n",
    "        super().__init__(kernel_size, stride)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.weight, self.bias = self.init_weights_and_bias(\n",
    "            weight_loc, bias_loc)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"No-op for pretrained weights. Provided for API compatibility.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _apply_padding(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply zero padding to the input array if required.\n",
    "        Args:\n",
    "            x (np.ndarray): Input array of shape (b, c, h, w).\n",
    "        Returns:\n",
    "            np.ndarray: Padded input array.\n",
    "        \"\"\"\n",
    "        if self.padding == 0:\n",
    "            return x\n",
    "        return np.pad(\n",
    "            x,\n",
    "            pad_width=((0, 0), (0, 0), (self.padding, self.padding),\n",
    "                       (self.padding, self.padding)),\n",
    "            mode='constant',\n",
    "            constant_values=0,\n",
    "        )\n",
    "\n",
    "    @profile_forward()\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Perform the forward pass using im2col + matrix multiply.\n",
    "        Args:\n",
    "            x (np.ndarray): Input array of shape (B, C_in, H, W).\n",
    "        Returns:\n",
    "            np.ndarray: Output array of shape (B, C_out, H_out, W_out).\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "        k = self.kernel_size\n",
    "        x_pad = self._apply_padding(x)\n",
    "        H_p, W_p = x_pad.shape[2:]\n",
    "        out_h = (H_p - k) // self.stride + 1\n",
    "        out_w = (W_p - k) // self.stride + 1\n",
    "\n",
    "        windows = self._patch_with_stride(x_pad)\n",
    "\n",
    "        # Reshape to (B*out_h*out_w, C*k*k)\n",
    "        col = windows.reshape(B, C, out_h, out_w, k * k)\n",
    "        col = col.transpose(0, 2, 3, 1, 4).reshape(\n",
    "            B * out_h * out_w, C * k * k)\n",
    "\n",
    "        # Weight reshape: (C_out, C*k*k)\n",
    "        w_mat = self.weight.reshape(self.out_channels, C * k * k)\n",
    "\n",
    "        # GEMM: (N, C*k*k) @ (C*k*k, C_out) -> (N, C_out)\n",
    "        out_mat = col @ w_mat.T\n",
    "\n",
    "        # Reshape back: (B, out_h, out_w, C_out) -> (B, C_out, out_h, out_w)\n",
    "        out = out_mat.reshape(\n",
    "            B, out_h, out_w, self.out_channels).transpose(0, 3, 1, 2)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias[None, :, None, None]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e56b1",
   "metadata": {},
   "source": [
    "#### Custom ReLU\n",
    "\n",
    "A straightforward NumPy implementation of ReLU using `np.maximum`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bf053fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomReLU(NumpyModule):\n",
    "    \"\"\"\n",
    "    Custom ReLU activation layer using NumPy.\n",
    "\n",
    "    Applies the Rectified Linear Unit (ReLU) function: f(x)=max(0,x) element-wise.\n",
    "    \"\"\"\n",
    "\n",
    "    @profile_forward()\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply ReLU to the input.\n",
    "        Args:\n",
    "            x (np.ndarray): Input tensor of any shape.\n",
    "        Returns:\n",
    "            np.ndarray: Same shape as input with negatives zeroed.\n",
    "        \"\"\"\n",
    "        return np.maximum(x, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e33de1",
   "metadata": {},
   "source": [
    "#### Custom MaxPool2d\n",
    "\n",
    "Implemented via the same patch extraction utility as convolution, followed by a reduction (`np.max`) over the spatial kernel dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9152ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMaxPool2d(PatchMixin, NumpyModule):\n",
    "    \"\"\"\n",
    "    Custom Max Pooling layer using NumPy.\n",
    "\n",
    "    Extracts spatial patches then takes the maximum over each patch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: int, stride: int) -> None:\n",
    "        super().__init__(kernel_size, stride)\n",
    "\n",
    "    @profile_forward()\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply max pooling.\n",
    "        Args:\n",
    "            x (np.ndarray): Input of shape (batch, channels, height, width).\n",
    "        Returns:\n",
    "            np.ndarray: Pooled output.\n",
    "        \"\"\"\n",
    "        patched_windows = self._patch_with_stride(x)\n",
    "        return np.max(patched_windows, axis=(-2, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39ecc6",
   "metadata": {},
   "source": [
    "#### Custom Adaptive AvgPool2d\n",
    "\n",
    "Reduces arbitrary spatial dimensions to a fixed target by averaging over partitioned regions computed with integer floor/ceil boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60188491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAdaptiveAvgPool2d(NumpyModule):\n",
    "    \"\"\"\n",
    "    Adaptive Average Pooling layer implemented with NumPy.\n",
    "\n",
    "    Reduces spatial dimensions to a target (H_out, W_out) by averaging over\n",
    "    variable-sized input regions computed via integer partitioning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size: tuple[int, int]) -> None:\n",
    "        super().__init__()\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            self.output_size = output_size\n",
    "\n",
    "    @profile_forward()\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply adaptive average pooling.\n",
    "        Args:\n",
    "            x (np.ndarray): Input of shape (batch, channels, height, width).\n",
    "        Returns:\n",
    "            np.ndarray: Output of shape (batch, channels, H_out, W_out).\n",
    "        \"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        out_h, out_w = self.output_size\n",
    "        out = np.zeros((b, c, out_h, out_w), dtype=x.dtype)\n",
    "        for i in range(out_h):\n",
    "            h_start = int(np.floor(i * h / out_h))\n",
    "            h_end = int(np.ceil((i + 1) * h / out_h))\n",
    "            for j in range(out_w):\n",
    "                w_start = int(np.floor(j * w / out_w))\n",
    "                w_end = int(np.ceil((j + 1) * w / out_w))\n",
    "                region = x[:, :, h_start:h_end, w_start:w_end]\n",
    "                out[:, :, i, j] = region.mean(axis=(-2, -1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97264d",
   "metadata": {},
   "source": [
    "#### Custom Linear Module\n",
    "\n",
    "Uses `einsum` to express the matrix multiply `x W^T` cleanly, then adds the bias. Operates purely on NumPy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe6b05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EinopsLinear(WeightsAndBiasMixin, NumpyModule):\n",
    "    \"\"\"\n",
    "    Custom Linear (fully connected) layer using NumPy and einops.\n",
    "\n",
    "    Performs y = x W^T + b via einsum for clarity.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, weight_loc: str, bias_loc: str):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight, self.bias = self.init_weights_and_bias(\n",
    "            weight_loc, bias_loc)\n",
    "\n",
    "    @profile_forward()\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Forward pass.\n",
    "        Args:\n",
    "            x (np.ndarray): Shape (batch, in_features).\n",
    "        Returns:\n",
    "            np.ndarray: Shape (batch, out_features).\n",
    "        \"\"\"\n",
    "        y = einsum(x, self.weight, \"b i, o i -> b o\")\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd790db",
   "metadata": {},
   "source": [
    "#### AlexNet Class Implementation\n",
    "\n",
    "Assembles the feature extractor, adaptive pooling, and classifier blocks using the custom NumPy-based layers defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feb5b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(NumpyModule):\n",
    "    \"\"\"\n",
    "    Custom AlexNet implementation using NumPy for educational inference.\n",
    "\n",
    "    Replicates the original AlexNet architecture with all major layers\n",
    "    (convolution, pooling, linear, activation) implemented from scratch\n",
    "    operating on NumPy arrays. Pretrained weights are loaded from the\n",
    "    torchvision reference model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int = 1000) -> None:\n",
    "        super().__init__()\n",
    "        self.features = NumpySequential(\n",
    "            CustomConv2d(3, 64, kernel_size=11, stride=4, padding=2,\n",
    "                         weight_loc='features.0.weight', bias_loc='features.0.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomMaxPool2d(kernel_size=3, stride=2),\n",
    "            CustomConv2d(64, 192, kernel_size=5, padding=2,\n",
    "                         weight_loc='features.3.weight', bias_loc='features.3.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomMaxPool2d(kernel_size=3, stride=2),\n",
    "            CustomConv2d(192, 384, kernel_size=3, padding=1,\n",
    "                         weight_loc='features.6.weight', bias_loc='features.6.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomConv2d(384, 256, kernel_size=3, padding=1,\n",
    "                         weight_loc='features.8.weight', bias_loc='features.8.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomConv2d(256, 256, kernel_size=3, padding=1,\n",
    "                         weight_loc='features.10.weight', bias_loc='features.10.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomMaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = CustomAdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = NumpySequential(\n",
    "            EinopsLinear(256 * 6 * 6, 4096, weight_loc='classifier.1.weight',\n",
    "                         bias_loc='classifier.1.bias'),\n",
    "            CustomReLU(),\n",
    "            EinopsLinear(4096, 4096, weight_loc='classifier.4.weight',\n",
    "                         bias_loc='classifier.4.bias'),\n",
    "            CustomReLU(),\n",
    "            EinopsLinear(4096, num_classes, weight_loc='classifier.6.weight',\n",
    "                         bias_loc='classifier.6.bias'),\n",
    "        )\n",
    "\n",
    "    @profile_forward(\"AlexNet.forward\")\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Forward pass.\n",
    "        Args:\n",
    "            x (np.ndarray): (batch, 3, 224, 224)\n",
    "        Returns:\n",
    "            np.ndarray: (batch, num_classes) class scores.\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        b = x.shape[0]\n",
    "        x = x.reshape(b, -1)  # flatten\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec05e96",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Run a forward pass over the validation set, accumulating accuracy using NumPy operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b532ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 1/196 [00:06<20:30,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Acc: 0.6836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 2/196 [00:11<17:58,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Acc: 0.7109\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# Estimate total batches for progress bar length\n",
    "try:\n",
    "    total_batches = len(val_dataloader)\n",
    "except TypeError:\n",
    "    total_batches = None\n",
    "\n",
    "for images, labels in tqdm(val_dataloader, total=total_batches, desc=\"Evaluating\", leave=True):\n",
    "    # images, labels already NumPy from collate\n",
    "    outputs = model.forward(images)  # (b, num_classes) np.ndarray\n",
    "    predicted = np.argmax(outputs, axis=1)\n",
    "    total += int(labels.shape[0])\n",
    "    correct += int((predicted == labels).sum())\n",
    "    running_acc = correct / total if total else 0.0\n",
    "    tqdm.write(f\"Running Acc: {running_acc:.4f}\")\n",
    "\n",
    "accuracy = correct / total if total else 0.0\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696fc64",
   "metadata": {},
   "source": [
    "#### Profile Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0cc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                  Calls    Total(ms)     Mean(ms)      Max(ms)\n",
      "-------------------------------------------------------------------\n",
      "AlexNet.forward          196   814450.369     4155.359     4448.856\n",
      "EinopsLinear             588   401987.004      683.651     1777.427\n",
      "CustomConv2d             980   384456.266      392.302      646.020\n",
      "CustomMaxPool2d          588    14866.174       25.283       56.330\n",
      "CustomReLU              1372    11949.694        8.710       34.999\n",
      "CustomAdaptiveAvgPool2d   196      739.565        3.773        6.927\n",
      "-------------------------------------------------------------------\n",
      "Total profiled time: 1628449.07 ms across 3920 calls\n"
     ]
    }
   ],
   "source": [
    "profile_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai231",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
