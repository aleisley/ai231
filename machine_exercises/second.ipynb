{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82811892",
   "metadata": {},
   "source": [
    "### ME2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65963a",
   "metadata": {},
   "source": [
    "#### Import necessary packages\n",
    "\n",
    "This notebook demonstrates custom deep learning inference using CuPy for GPU acceleration.\n",
    "\n",
    "- **CuPy** is the core library enabling fast, GPU-based array operations and custom neural network layers. All major computations (convolution, pooling, linear layers) are performed on the GPU using CuPy arrays.\n",
    "- We also use PyTorch and torchvision for data loading and to access pretrained AlexNet weights, but the model itself is implemented from scratch with CuPy.\n",
    "- Other packages (einops, tqdm, etc.) support tensor algebra and progress monitoring.\n",
    "\n",
    "The imports below are grouped to highlight standard libraries, third-party utilities, and GPU/CuPy-specific tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb363a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleisley/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "from typing import Tuple\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from einops import einsum, rearrange\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision.models import AlexNet_Weights\n",
    "\n",
    "# GPU/CuPy imports\n",
    "import cupy as cp\n",
    "from cupy.lib.stride_tricks import sliding_window_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526892a",
   "metadata": {},
   "source": [
    "#### Load the weights and biases of AlexNet\n",
    "\n",
    "In this section, we extract the pretrained weights and biases from torchvision's AlexNet model.\n",
    "\n",
    "- The weights and biases are loaded using the default configuration from `AlexNet_Weights`.\n",
    "- These parameters are stored in a dictionary and printed to verify the available keys.\n",
    "- Our custom layers will use these pretrained values for inference, ensuring the model matches the original AlexNet architecture.\n",
    "\n",
    "This step is essential for initializing all custom layers with correct parameters before running inference on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ee8f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['features.0.weight', 'features.0.bias', 'features.3.weight', 'features.3.bias', 'features.6.weight', 'features.6.bias', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])\n"
     ]
    }
   ],
   "source": [
    "weights_and_biases = AlexNet_Weights.DEFAULT.get_state_dict()\n",
    "print(weights_and_biases.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5429bfd",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "In this section, we load the ImageNet validation dataset and prepare it for inference with our custom AlexNet implementation.\n",
    "\n",
    "- We use torchvision's `ImageNet` class to access the validation split, applying the standard AlexNet preprocessing transforms.\n",
    "- The DataLoader is configured to efficiently batch and serve images for evaluation.\n",
    "- A custom `default_collate` function is used to convert PyTorch tensors to CuPy arrays, enabling GPU-accelerated inference with our custom layers.\n",
    "- The batch size and worker settings are chosen to avoid multiprocessing issues with GPU contexts.\n",
    "\n",
    "This setup allows us to run high-throughput inference on the validation set using a fully custom, CuPy-based AlexNet model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8698e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_collate(batch):\n",
    "    \"\"\"\n",
    "    A collation function that simply returns the batch as is.\n",
    "    We convert torch tensors to numpy arrays since cp.pad doesn't work on tensors\n",
    "    \"\"\"\n",
    "    imgs, labels = zip(*batch)  # imgs: tuple[torch.Tensor], labels: tuple[int]\n",
    "    imgs = [cp.asarray(img.numpy(), dtype=cp.float32) for img in imgs]\n",
    "    imgs = cp.stack(imgs, axis=0)                      # [B,3,224,224]\n",
    "    labels = cp.asarray(labels, dtype=cp.int64)        # [B]\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "# implement using ImageNet\n",
    "imagenet_val = ImageNet(\n",
    "    root=\"data/ImageNet1k\",\n",
    "    split=\"val\",\n",
    "    transform=AlexNet_Weights.IMAGENET1K_V1.transforms()\n",
    ")\n",
    "\n",
    "# the dataloader automatically segregates the labels\n",
    "val_dataloader = DataLoader(\n",
    "    imagenet_val,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=default_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11075a2b",
   "metadata": {},
   "source": [
    "#### Define the custom Conv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552c4b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMixin:\n",
    "    \"\"\"Mixin for extracting patches from input arrays with a given kernel size and stride.\n",
    "    Used for convolution and pooling operations on CuPy arrays.\"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: int, stride: int) -> None:\n",
    "        \"\"\"Initialize patch extraction parameters.\n",
    "        Args:\n",
    "            kernel_size (int): Size of the square kernel.\n",
    "            stride (int): Stride for patch extraction.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def _patch_with_stride(self, x_pad: cp.ndarray) -> cp.ndarray:\n",
    "        \"\"\"Extract k x k patches from the input array with the given stride.\n",
    "        Args:\n",
    "            x_pad (cp.ndarray): Input array of shape (b, c, h, w).\n",
    "        Returns:\n",
    "            cp.ndarray: Array of shape (b, c, h/stride, w/stride, k, k) containing the extracted patches.\n",
    "        \"\"\"\n",
    "        windows = sliding_window_view(  # type: ignore\n",
    "            x_pad,\n",
    "            window_shape=(self.kernel_size, self.kernel_size),\n",
    "            axis=(-2, -1)  # type: ignore\n",
    "        )\n",
    "        return windows[:, :, ::self.stride, ::self.stride, :, :]\n",
    "\n",
    "\n",
    "class WeightsAndBiasMixin:\n",
    "    \"\"\"Mixin for loading pretrained weights and biases from a state dict and converting to CuPy arrays.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        \"\"\"Initialize the mixin (calls super).\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def init_weights_and_bias(self, weight_loc: str, bias_loc: str) -> Tuple[cp.ndarray, cp.ndarray]:\n",
    "        \"\"\"Load weights and biases from the state dict and convert to CuPy arrays.\n",
    "        Args:\n",
    "            weight_loc (str): Key for weights in the state dict.\n",
    "            bias_loc (str): Key for biases in the state dict.\n",
    "        Returns:\n",
    "            Tuple[cp.ndarray, cp.ndarray]: CuPy arrays for weights and biases.\n",
    "        \"\"\"\n",
    "        weight_np = weights_and_biases[weight_loc].detach().cpu().numpy()\n",
    "        bias_np = weights_and_biases[bias_loc].detach().cpu().numpy()\n",
    "        weight = cp.asarray(weight_np)\n",
    "        bias = cp.asarray(bias_np)\n",
    "        return weight, bias\n",
    "\n",
    "\n",
    "class CustomConv2d(WeightsAndBiasMixin, PatchMixin, nn.Module):\n",
    "    \"\"\"\n",
    "    Custom 2D Convolution layer using CuPy, Einops, and einsum.\n",
    "    Performs convolution on CuPy arrays for GPU acceleration.\n",
    "    Limited shape flexibility for demonstration/inference.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        stride: int = 1,\n",
    "        padding: int = 0,\n",
    "        weight_loc: str = '',\n",
    "        bias_loc: str = '',\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the convolution layer with parameters and pretrained weights/biases.\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int): Size of the convolution kernel.\n",
    "            stride (int, optional): Stride for convolution. Defaults to 1.\n",
    "            padding (int, optional): Padding for input. Defaults to 0.\n",
    "            weight_loc (str, optional): Key for weights in state dict.\n",
    "            bias_loc (str, optional): Key for biases in state dict.\n",
    "        \"\"\"\n",
    "        super().__init__(kernel_size, stride)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.weight, self.bias = self.init_weights_and_bias(\n",
    "            weight_loc, bias_loc)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"No-op for pretrained weights. Provided for API compatibility.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _apply_padding(self, x: cp.ndarray) -> cp.ndarray:\n",
    "        \"\"\"Apply zero padding to the input array if required.\n",
    "        Args:\n",
    "            x (cp.ndarray): Input array of shape (b, c, h, w).\n",
    "        Returns:\n",
    "            cp.ndarray: Padded input array.\n",
    "        \"\"\"\n",
    "        if self.padding == 0:\n",
    "            return x\n",
    "        return cp.pad(\n",
    "            x,\n",
    "            pad_width=((0, 0), (0, 0), (self.padding, self.padding),\n",
    "                       (self.padding, self.padding)),\n",
    "            mode='constant',\n",
    "            constant_values=0,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: cp.ndarray) -> cp.ndarray:\n",
    "        \"\"\"Perform the forward pass of the convolution layer.\n",
    "        Args:\n",
    "            x (cp.ndarray): Input array of shape (b, c, h, w).\n",
    "        Returns:\n",
    "            cp.ndarray: Output array after convolution and bias addition.\n",
    "        \"\"\"\n",
    "        x_pad = self._apply_padding(x)\n",
    "        patched_windows = self._patch_with_stride(x_pad)\n",
    "        pre_activation = einsum(\n",
    "            patched_windows, self.weight, 'b c w h kw kh, o c kw kh -> b o w h')\n",
    "        return pre_activation + self.bias[None, :, None, None]  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e56b1",
   "metadata": {},
   "source": [
    "#### Custom ReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf053fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom ReLU activation layer using CuPy for GPU acceleration.\n",
    "\n",
    "    This layer applies the Rectified Linear Unit (ReLU) function to its input, setting all negative values to zero.\n",
    "    All operations are performed on CuPy arrays for efficient GPU computation.\n",
    "    Compatible with PyTorch's nn.Module interface for easy integration into custom models.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x: cp.ndarray) -> cp.ndarray:\n",
    "        \"\"\"\n",
    "        Apply the ReLU activation function to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (cp.ndarray): Input tensor (CuPy array) of any shape.\n",
    "\n",
    "        Returns:\n",
    "            cp.ndarray: Output tensor with negative values set to zero, same shape as input.\n",
    "        \"\"\"\n",
    "        return cp.maximum(x, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e33de1",
   "metadata": {},
   "source": [
    "#### Custom MaxPool2d\n",
    "\n",
    "This section introduces our custom Max Pooling layer, implemented from scratch for GPU acceleration using CuPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9152ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMaxPool2d(PatchMixin, nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Max Pooling layer using CuPy for GPU acceleration.\n",
    "\n",
    "    This layer performs max pooling by extracting patches from the input tensor and selecting the maximum value from each patch.\n",
    "    All operations are performed on CuPy arrays for efficient GPU computation.\n",
    "    Compatible with PyTorch's nn.Module interface for easy integration into custom models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: int, stride: int) -> None:\n",
    "        super().__init__(kernel_size, stride)\n",
    "\n",
    "    def forward(self, x: cp.ndarray) -> cp.ndarray:\n",
    "        \"\"\"\n",
    "        Apply max pooling to the input tensor using the specified kernel size and stride.\n",
    "\n",
    "        Args:\n",
    "            x (cp.ndarray): Input tensor (CuPy array) of shape (batch, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            cp.ndarray: Output tensor after max pooling, reduced spatial dimensions.\n",
    "        \"\"\"\n",
    "        patched_windows = self._patch_with_stride(x)\n",
    "        return cp.max(patched_windows, axis=(-2, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39ecc6",
   "metadata": {},
   "source": [
    "#### Custom Adaptive AvgPool2d\n",
    "\n",
    "This section introduces our custom Adaptive Average Pooling layer, implemented for GPU acceleration using CuPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60188491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAdaptiveAvgPool2d(nn.Module):\n",
    "    \"\"\"\n",
    "    This layer reduces the spatial dimensions of the input tensor to a fixed output size by averaging over dynamically computed regions.\n",
    "    All operations are performed on CuPy arrays for efficient GPU computation.\n",
    "    Compatible with PyTorch's nn.Module interface for easy integration into custom models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size: tuple[int, int]) -> None:\n",
    "        super().__init__()\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def forward(self, x: cp.ndarray) -> cp.ndarray:\n",
    "        \"\"\"\n",
    "        Apply adaptive average pooling to the input tensor to produce a fixed output size.\n",
    "\n",
    "        Args:\n",
    "            x (cp.ndarray): Input tensor (CuPy array) of shape (batch, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            cp.ndarray: Output tensor of shape (batch, channels, output_height, output_width) after adaptive average pooling.\n",
    "        \"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        out_h, out_w = self.output_size\n",
    "        out = cp.zeros((b, c, out_h, out_w), dtype=x.dtype)\n",
    "        for i in range(out_h):\n",
    "            h_start = int(cp.floor(i * h / out_h))\n",
    "            h_end = int(cp.ceil((i + 1) * h / out_h))\n",
    "            for j in range(out_w):\n",
    "                w_start = int(cp.floor(j * w / out_w))\n",
    "                w_end = int(cp.ceil((j + 1) * w / out_w))\n",
    "                region = x[:, :, h_start:h_end, w_start:w_end]\n",
    "                out[:, :, i, j] = region.mean(axis=(-2, -1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97264d",
   "metadata": {},
   "source": [
    "#### Custom Linear Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6b05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EinopsLinear(WeightsAndBiasMixin, nn.Module):\n",
    "    \"\"\"\n",
    "    Custom Linear (fully connected) layer using CuPy and einops for GPU-accelerated inference.\n",
    "\n",
    "    This layer performs matrix multiplication between input features and learned weights, followed by bias addition. All operations are performed on CuPy arrays for efficient GPU computation.\n",
    "    The implementation uses einops's einsum for concise and flexible tensor algebra, making the code readable and efficient.\n",
    "    Pretrained weights and biases from AlexNet are loaded and used to initialize the layer, ensuring compatibility with the original architecture.\n",
    "    Compatible with PyTorch's nn.Module interface for easy integration into custom models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, weight_loc: str, bias_loc: str):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight, self.bias = self.init_weights_and_bias(\n",
    "            weight_loc, bias_loc)\n",
    "\n",
    "    def forward(self, x: cp.ndarray) -> cp.ndarray:\n",
    "        \"\"\"\n",
    "        Perform the forward pass of the linear layer using einsum for matrix multiplication and bias addition.\n",
    "\n",
    "        Args:\n",
    "            x (cp.ndarray): Input tensor of shape (batch, in_features), CuPy array.\n",
    "\n",
    "        Returns:\n",
    "            cp.ndarray: Output tensor of shape (batch, out_features) after linear transformation and bias addition.\n",
    "        \"\"\"\n",
    "        y = einsum(x, self.weight, \"b i, o i -> b o\")\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd790db",
   "metadata": {},
   "source": [
    "#### AlexNet Class Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb5b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom AlexNet implementation using CuPy for GPU-accelerated inference.\n",
    "\n",
    "    This class replicates the original AlexNet architecture with all major layers (convolution, pooling, linear, activation) implemented from scratch using CuPy arrays for fast GPU computation.\n",
    "    The model loads pretrained weights and biases from torchvision's AlexNet, ensuring compatibility and matching performance for inference.\n",
    "    The pipeline consists of feature extraction (convolutions, activations, pooling), adaptive average pooling, and a classifier (fully connected layers).\n",
    "    All layers are compatible with PyTorch's nn.Module interface, but computations are performed on CuPy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int = 1000) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            CustomConv2d(3, 64, kernel_size=11, stride=4, padding=2,\n",
    "                         weight_loc='features.0.weight', bias_loc='features.0.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomMaxPool2d(kernel_size=3, stride=2),\n",
    "            CustomConv2d(64, 192, kernel_size=5, padding=2,\n",
    "                         weight_loc='features.3.weight', bias_loc='features.3.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomMaxPool2d(kernel_size=3, stride=2),\n",
    "            CustomConv2d(192, 384, kernel_size=3, padding=1,\n",
    "                         weight_loc='features.6.weight', bias_loc='features.6.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomConv2d(384, 256, kernel_size=3, padding=1,\n",
    "                         weight_loc='features.8.weight', bias_loc='features.8.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomConv2d(256, 256, kernel_size=3, padding=1,\n",
    "                         weight_loc='features.10.weight', bias_loc='features.10.bias'),\n",
    "            CustomReLU(),\n",
    "            CustomMaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = CustomAdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            EinopsLinear(256 * 6 * 6, 4096, weight_loc='classifier.1.weight',\n",
    "                         bias_loc='classifier.1.bias'),\n",
    "            CustomReLU(),\n",
    "            EinopsLinear(4096, 4096, weight_loc='classifier.4.weight',\n",
    "                         bias_loc='classifier.4.bias'),\n",
    "            CustomReLU(),\n",
    "            EinopsLinear(4096, num_classes, weight_loc='classifier.6.weight',\n",
    "                         bias_loc='classifier.6.bias'),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: cp.ndarray) -> cp.ndarray:\n",
    "        \"\"\"\n",
    "        Perform the forward pass of the AlexNet model on CuPy arrays.\n",
    "\n",
    "        Args:\n",
    "            x (cp.ndarray): Input tensor of shape (batch, 3, 224, 224), CuPy array.\n",
    "\n",
    "        Returns:\n",
    "            cp.ndarray: Output tensor of shape (batch, num_classes) with class scores.\n",
    "\n",
    "        Workflow:\n",
    "            1. Feature extraction using custom convolution, activation, and pooling layers.\n",
    "            2. Adaptive average pooling to reduce spatial dimensions.\n",
    "            3. Flattening and classification using custom linear layers.\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        b = x.shape[0]\n",
    "        x = x.reshape(b, -1)  # flatten\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f166f7",
   "metadata": {},
   "source": [
    "#### Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b532ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/98 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "CompileException",
     "evalue": "In file included from /tmp/comgr-e79635/input/tmp/tmpihyv30dr/74f19f81b237cf4c57963c764cfafe03926df9ca.hsaco.cu:2:\nIn file included from /home/aleisley/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_core/include/cupy/carray.cuh:40:\n/usr/lib/gcc/x86_64-redhat-linux/15/../../../../include/c++/15/cstddef:52:10: fatal error: 'stddef.h' file not found\n   52 | #include <stddef.h>\n      |          ^~~~~~~~~~\n1 error generated when compiling for gfx1101.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNVRTCError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:731\u001b[39m, in \u001b[36m_NVRTCProgram.compile\u001b[39m\u001b[34m(self, options, log_stream)\u001b[39m\n\u001b[32m    730\u001b[39m         nvrtc.addNameExpression(\u001b[38;5;28mself\u001b[39m.ptr, ker)\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[43mnvrtc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompileProgram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m mapping = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:125\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.compileProgram\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:138\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.compileProgram\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:53\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mNVRTCError\u001b[39m: HIPRTC_ERROR_COMPILATION (6)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCompileException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     11\u001b[39m     total_batches = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluating\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ensure CuPy arrays\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m      6\u001b[39m imgs, labels = \u001b[38;5;28mzip\u001b[39m(*batch)  \u001b[38;5;66;03m# imgs: tuple[torch.Tensor], labels: tuple[int]\u001b[39;00m\n\u001b[32m      7\u001b[39m imgs = [cp.asarray(img.numpy(), dtype=cp.float32) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m imgs]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m imgs = \u001b[43mcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m                      \u001b[38;5;66;03m# [B,3,224,224]\u001b[39;00m\n\u001b[32m      9\u001b[39m labels = cp.asarray(labels, dtype=cp.int64)        \u001b[38;5;66;03m# [B]\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m imgs, labels\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_manipulation/join.py:151\u001b[39m, in \u001b[36mstack\u001b[39m\u001b[34m(tup, axis, out, dtype, casting)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstack\u001b[39m(tup, axis=\u001b[32m0\u001b[39m, out=\u001b[38;5;28;01mNone\u001b[39;00m, *, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, casting=\u001b[33m'\u001b[39m\u001b[33msame_kind\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    134\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Stacks arrays along a new axis.\u001b[39;00m\n\u001b[32m    135\u001b[39m \n\u001b[32m    136\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    149\u001b[39m \u001b[33;03m    .. seealso:: :func:`numpy.stack`\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcupy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtup\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_manipulation/join.py:60\u001b[39m, in \u001b[36mconcatenate\u001b[39m\u001b[34m(tup, axis, out, dtype, casting)\u001b[39m\n\u001b[32m     58\u001b[39m     tup = [m.ravel() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tup]\n\u001b[32m     59\u001b[39m     axis = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_routines_manipulation.pyx:586\u001b[39m, in \u001b[36mcupy._core._routines_manipulation.concatenate_method\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_routines_manipulation.pyx:665\u001b[39m, in \u001b[36mcupy._core._routines_manipulation.concatenate_method\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_routines_manipulation.pyx:695\u001b[39m, in \u001b[36mcupy._core._routines_manipulation._concatenate\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_routines_manipulation.pyx:819\u001b[39m, in \u001b[36mcupy._core._routines_manipulation._concatenate_single_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:920\u001b[39m, in \u001b[36mcupy._core._kernel.ElementwiseKernel.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:945\u001b[39m, in \u001b[36mcupy._core._kernel.ElementwiseKernel._get_elementwise_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_util.pyx:67\u001b[39m, in \u001b[36mcupy._util.memoize.decorator.ret\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:728\u001b[39m, in \u001b[36mcupy._core._kernel._get_elementwise_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:82\u001b[39m, in \u001b[36mcupy._core._kernel._get_simple_elementwise_kernel_from_code\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/core.pyx:2377\u001b[39m, in \u001b[36mcupy._core.core.compile_with_cache\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:532\u001b[39m, in \u001b[36m_compile_module_with_cache\u001b[39m\u001b[34m(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, jitify)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m runtime.is_hip:\n\u001b[32m    531\u001b[39m     backend = \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == \u001b[33m'\u001b[39m\u001b[33mnvrtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mhipcc\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_with_cache_hip\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile_with_cache_cuda(\n\u001b[32m    537\u001b[39m         source, options, arch, cache_dir, extra_source, backend,\n\u001b[32m    538\u001b[39m         enable_cooperative_groups, name_expressions, log_stream,\n\u001b[32m    539\u001b[39m         cache_in_memory, jitify)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:955\u001b[39m, in \u001b[36m_compile_with_cache_hip\u001b[39m\u001b[34m(source, options, arch, cache_dir, extra_source, backend, name_expressions, log_stream, cache_in_memory, use_converter)\u001b[39m\n\u001b[32m    951\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    954\u001b[39m     \u001b[38;5;66;03m# compile_using_nvrtc calls hiprtc for hip builds\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     binary, mapping = \u001b[43mcompile_using_nvrtc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.cu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m     mod._set_mapping(mapping)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:370\u001b[39m, in \u001b[36mcompile_using_nvrtc\u001b[39m\u001b[34m(source, options, arch, filename, name_expressions, log_stream, cache_in_memory, jitify)\u001b[39m\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cu_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m cu_file:\n\u001b[32m    368\u001b[39m             cu_file.write(source)\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    373\u001b[39m     cu_path = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jitify \u001b[38;5;28;01melse\u001b[39;00m filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:354\u001b[39m, in \u001b[36mcompile_using_nvrtc.<locals>._compile\u001b[39m\u001b[34m(source, options, cu_path, name_expressions, log_stream, jitify)\u001b[39m\n\u001b[32m    351\u001b[39m prog = _NVRTCProgram(source, cu_path, headers, include_names,\n\u001b[32m    352\u001b[39m                      name_expressions=name_expressions, method=method)\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     compiled_obj, mapping = \u001b[43mprog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CompileException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    356\u001b[39m     dump = _get_bool_env_variable(\n\u001b[32m    357\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCUPY_DUMP_CUDA_SOURCE_ON_ERROR\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:750\u001b[39m, in \u001b[36m_NVRTCProgram.compile\u001b[39m\u001b[34m(self, options, log_stream)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m nvrtc.NVRTCError:\n\u001b[32m    749\u001b[39m     log = nvrtc.getProgramLog(\u001b[38;5;28mself\u001b[39m.ptr)\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CompileException(log, \u001b[38;5;28mself\u001b[39m.src, \u001b[38;5;28mself\u001b[39m.name, options,\n\u001b[32m    751\u001b[39m                            \u001b[33m'\u001b[39m\u001b[33mnvrtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runtime.is_hip \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mCompileException\u001b[39m: In file included from /tmp/comgr-e79635/input/tmp/tmpihyv30dr/74f19f81b237cf4c57963c764cfafe03926df9ca.hsaco.cu:2:\nIn file included from /home/aleisley/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_core/include/cupy/carray.cuh:40:\n/usr/lib/gcc/x86_64-redhat-linux/15/../../../../include/c++/15/cstddef:52:10: fatal error: 'stddef.h' file not found\n   52 | #include <stddef.h>\n      |          ^~~~~~~~~~\n1 error generated when compiling for gfx1101."
     ]
    }
   ],
   "source": [
    "model = AlexNet()\n",
    "model.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# Estimate total batches for progress bar length\n",
    "try:\n",
    "    total_batches = len(val_dataloader)\n",
    "except TypeError:\n",
    "    total_batches = None\n",
    "\n",
    "for images, labels in tqdm(val_dataloader, total=total_batches, desc=\"Evaluating\", leave=True):\n",
    "    # ensure CuPy arrays\n",
    "    if isinstance(images, torch.Tensor):\n",
    "        images = cp.asarray(images.numpy())\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = cp.asarray(labels.numpy())\n",
    "\n",
    "    outputs = model.forward(images)  # (b, num_classes) cp.ndarray\n",
    "    predicted = cp.argmax(outputs, axis=1)\n",
    "    total += int(labels.shape[0])\n",
    "    correct += int((predicted == labels).sum())\n",
    "    running_acc = correct / total if total else 0.0\n",
    "    tqdm.write(f\"Running Acc: {running_acc:.4f}\")\n",
    "\n",
    "accuracy = correct / total if total else 0.0\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce1c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /home/aleisley/Documents/mengai/ai231/.venv/bin/python\n",
      "CuPy: 13.6.0\n",
      "is_hip: True\n",
      "device_count: 1\n",
      "dev 0: AMD Radeon RX 7800 XT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import cupy as cp\n",
    "import cupy.cuda.runtime as rt\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"CuPy:\", cp.__version__)\n",
    "print(\"is_hip:\", rt.is_hip)\n",
    "\n",
    "try:\n",
    "    n = rt.getDeviceCount()\n",
    "    print(\"device_count:\", n)\n",
    "    for i in range(n):\n",
    "        props = rt.getDeviceProperties(i)\n",
    "        print(f\"dev {i}:\", props[\"name\"].decode())\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"ENV HINTS:\")\n",
    "    print(\"  ROCM_PATH=\", os.environ.get(\"ROCM_PATH\"))\n",
    "    print(\"  LD_LIBRARY_PATH=\", os.environ.get(\"LD_LIBRARY_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6823d90",
   "metadata": {},
   "outputs": [
    {
     "ename": "CompileException",
     "evalue": "In file included from /tmp/comgr-301093/input/tmp/tmp450x8gjs/3b99542c99c6c5d523766e96f43cf1bf3bea5a43.hsaco.cu:2:\nIn file included from /home/aleisley/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_core/include/cupy/carray.cuh:40:\n/usr/lib/gcc/x86_64-redhat-linux/15/../../../../include/c++/15/cstddef:52:10: fatal error: 'stddef.h' file not found\n   52 | #include <stddef.h>\n      |          ^~~~~~~~~~\n1 error generated when compiling for gfx1101.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNVRTCError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:731\u001b[39m, in \u001b[36m_NVRTCProgram.compile\u001b[39m\u001b[34m(self, options, log_stream)\u001b[39m\n\u001b[32m    730\u001b[39m         nvrtc.addNameExpression(\u001b[38;5;28mself\u001b[39m.ptr, ker)\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[43mnvrtc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompileProgram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m mapping = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:125\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.compileProgram\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:138\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.compileProgram\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:53\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mNVRTCError\u001b[39m: HIPRTC_ERROR_COMPILATION (6)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCompileException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcupy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# import os\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# os.environ[\"CUPY_HIPRTC_EXTRA_OPTIONS\"] = (\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#     \"--std=c++17 \"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#     \"--include-path=/usr/lib/gcc/x86_64-redhat-linux/15/include \"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#     \"--include-path=/usr/lib/gcc/x86_64-redhat-linux/15/include-fixed\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m.sum())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_creation/ranges.py:60\u001b[39m, in \u001b[36marange\u001b[39m\u001b[34m(start, stop, step, dtype)\u001b[39m\n\u001b[32m     58\u001b[39m ret = cupy.empty((size,), dtype=dtype)\n\u001b[32m     59\u001b[39m typ = numpy.dtype(dtype).type\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m_arange_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:1374\u001b[39m, in \u001b[36mcupy._core._kernel.ufunc.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:1401\u001b[39m, in \u001b[36mcupy._core._kernel.ufunc._get_ufunc_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:1082\u001b[39m, in \u001b[36mcupy._core._kernel._get_ufunc_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:94\u001b[39m, in \u001b[36mcupy._core._kernel._get_simple_elementwise_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:82\u001b[39m, in \u001b[36mcupy._core._kernel._get_simple_elementwise_kernel_from_code\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/core.pyx:2377\u001b[39m, in \u001b[36mcupy._core.core.compile_with_cache\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:532\u001b[39m, in \u001b[36m_compile_module_with_cache\u001b[39m\u001b[34m(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, jitify)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m runtime.is_hip:\n\u001b[32m    531\u001b[39m     backend = \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == \u001b[33m'\u001b[39m\u001b[33mnvrtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mhipcc\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_with_cache_hip\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile_with_cache_cuda(\n\u001b[32m    537\u001b[39m         source, options, arch, cache_dir, extra_source, backend,\n\u001b[32m    538\u001b[39m         enable_cooperative_groups, name_expressions, log_stream,\n\u001b[32m    539\u001b[39m         cache_in_memory, jitify)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:955\u001b[39m, in \u001b[36m_compile_with_cache_hip\u001b[39m\u001b[34m(source, options, arch, cache_dir, extra_source, backend, name_expressions, log_stream, cache_in_memory, use_converter)\u001b[39m\n\u001b[32m    951\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    954\u001b[39m     \u001b[38;5;66;03m# compile_using_nvrtc calls hiprtc for hip builds\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     binary, mapping = \u001b[43mcompile_using_nvrtc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.cu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m     mod._set_mapping(mapping)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:370\u001b[39m, in \u001b[36mcompile_using_nvrtc\u001b[39m\u001b[34m(source, options, arch, filename, name_expressions, log_stream, cache_in_memory, jitify)\u001b[39m\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cu_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m cu_file:\n\u001b[32m    368\u001b[39m             cu_file.write(source)\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    373\u001b[39m     cu_path = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jitify \u001b[38;5;28;01melse\u001b[39;00m filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:354\u001b[39m, in \u001b[36mcompile_using_nvrtc.<locals>._compile\u001b[39m\u001b[34m(source, options, cu_path, name_expressions, log_stream, jitify)\u001b[39m\n\u001b[32m    351\u001b[39m prog = _NVRTCProgram(source, cu_path, headers, include_names,\n\u001b[32m    352\u001b[39m                      name_expressions=name_expressions, method=method)\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     compiled_obj, mapping = \u001b[43mprog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CompileException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    356\u001b[39m     dump = _get_bool_env_variable(\n\u001b[32m    357\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCUPY_DUMP_CUDA_SOURCE_ON_ERROR\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:750\u001b[39m, in \u001b[36m_NVRTCProgram.compile\u001b[39m\u001b[34m(self, options, log_stream)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m nvrtc.NVRTCError:\n\u001b[32m    749\u001b[39m     log = nvrtc.getProgramLog(\u001b[38;5;28mself\u001b[39m.ptr)\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CompileException(log, \u001b[38;5;28mself\u001b[39m.src, \u001b[38;5;28mself\u001b[39m.name, options,\n\u001b[32m    751\u001b[39m                            \u001b[33m'\u001b[39m\u001b[33mnvrtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runtime.is_hip \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mCompileException\u001b[39m: In file included from /tmp/comgr-301093/input/tmp/tmp450x8gjs/3b99542c99c6c5d523766e96f43cf1bf3bea5a43.hsaco.cu:2:\nIn file included from /home/aleisley/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_core/include/cupy/carray.cuh:40:\n/usr/lib/gcc/x86_64-redhat-linux/15/../../../../include/c++/15/cstddef:52:10: fatal error: 'stddef.h' file not found\n   52 | #include <stddef.h>\n      |          ^~~~~~~~~~\n1 error generated when compiling for gfx1101."
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "# import os\n",
    "# os.environ[\"CUPY_HIPRTC_EXTRA_OPTIONS\"] = (\n",
    "#     \"--std=c++17 \"\n",
    "#     \"--include-path=/usr/lib/gcc/x86_64-redhat-linux/15/include \"\n",
    "#     \"--include-path=/usr/lib/gcc/x86_64-redhat-linux/15/include-fixed\"\n",
    "# )\n",
    "\n",
    "print(cp.arange(10).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3029f7d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "CompileException",
     "evalue": "In file included from /tmp/comgr-9b34e6/input/tmp/tmpqr2ikmde/69c23a85c53435a76e586b8bcb294b7e7120df4e.hsaco.cu:2:\nIn file included from /home/aleisley/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_core/include/cupy/carray.cuh:40:\n/usr/lib/gcc/x86_64-redhat-linux/15/../../../../include/c++/15/cstddef:52:10: fatal error: 'stddef.h' file not found\n   52 | #include <stddef.h>\n      |          ^~~~~~~~~~\n1 error generated when compiling for gfx1101.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNVRTCError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:731\u001b[39m, in \u001b[36m_NVRTCProgram.compile\u001b[39m\u001b[34m(self, options, log_stream)\u001b[39m\n\u001b[32m    730\u001b[39m         nvrtc.addNameExpression(\u001b[38;5;28mself\u001b[39m.ptr, ker)\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m \u001b[43mnvrtc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompileProgram\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    732\u001b[39m mapping = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:125\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.compileProgram\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:138\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.compileProgram\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends/cuda/libs/nvrtc.pyx:53\u001b[39m, in \u001b[36mcupy_backends.cuda.libs.nvrtc.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mNVRTCError\u001b[39m: HIPRTC_ERROR_COMPILATION (6)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCompileException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcupy\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# x = cupy.array([1., 2., 3.])\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m y = \u001b[43mcupy\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_creation/ranges.py:60\u001b[39m, in \u001b[36marange\u001b[39m\u001b[34m(start, stop, step, dtype)\u001b[39m\n\u001b[32m     58\u001b[39m ret = cupy.empty((size,), dtype=dtype)\n\u001b[32m     59\u001b[39m typ = numpy.dtype(dtype).type\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m_arange_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:1374\u001b[39m, in \u001b[36mcupy._core._kernel.ufunc.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:1401\u001b[39m, in \u001b[36mcupy._core._kernel.ufunc._get_ufunc_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:1082\u001b[39m, in \u001b[36mcupy._core._kernel._get_ufunc_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:94\u001b[39m, in \u001b[36mcupy._core._kernel._get_simple_elementwise_kernel\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/_kernel.pyx:82\u001b[39m, in \u001b[36mcupy._core._kernel._get_simple_elementwise_kernel_from_code\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy/_core/core.pyx:2377\u001b[39m, in \u001b[36mcupy._core.core.compile_with_cache\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:532\u001b[39m, in \u001b[36m_compile_module_with_cache\u001b[39m\u001b[34m(source, options, arch, cache_dir, extra_source, backend, enable_cooperative_groups, name_expressions, log_stream, jitify)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m runtime.is_hip:\n\u001b[32m    531\u001b[39m     backend = \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == \u001b[33m'\u001b[39m\u001b[33mnvrtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mhipcc\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_with_cache_hip\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile_with_cache_cuda(\n\u001b[32m    537\u001b[39m         source, options, arch, cache_dir, extra_source, backend,\n\u001b[32m    538\u001b[39m         enable_cooperative_groups, name_expressions, log_stream,\n\u001b[32m    539\u001b[39m         cache_in_memory, jitify)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:955\u001b[39m, in \u001b[36m_compile_with_cache_hip\u001b[39m\u001b[34m(source, options, arch, cache_dir, extra_source, backend, name_expressions, log_stream, cache_in_memory, use_converter)\u001b[39m\n\u001b[32m    951\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend == \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    954\u001b[39m     \u001b[38;5;66;03m# compile_using_nvrtc calls hiprtc for hip builds\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     binary, mapping = \u001b[43mcompile_using_nvrtc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.cu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_in_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m     mod._set_mapping(mapping)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:370\u001b[39m, in \u001b[36mcompile_using_nvrtc\u001b[39m\u001b[34m(source, options, arch, filename, name_expressions, log_stream, cache_in_memory, jitify)\u001b[39m\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cu_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m cu_file:\n\u001b[32m    368\u001b[39m             cu_file.write(source)\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mname_expressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    373\u001b[39m     cu_path = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jitify \u001b[38;5;28;01melse\u001b[39;00m filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:354\u001b[39m, in \u001b[36mcompile_using_nvrtc.<locals>._compile\u001b[39m\u001b[34m(source, options, cu_path, name_expressions, log_stream, jitify)\u001b[39m\n\u001b[32m    351\u001b[39m prog = _NVRTCProgram(source, cu_path, headers, include_names,\n\u001b[32m    352\u001b[39m                      name_expressions=name_expressions, method=method)\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     compiled_obj, mapping = \u001b[43mprog\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CompileException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    356\u001b[39m     dump = _get_bool_env_variable(\n\u001b[32m    357\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCUPY_DUMP_CUDA_SOURCE_ON_ERROR\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/cuda/compiler.py:750\u001b[39m, in \u001b[36m_NVRTCProgram.compile\u001b[39m\u001b[34m(self, options, log_stream)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m nvrtc.NVRTCError:\n\u001b[32m    749\u001b[39m     log = nvrtc.getProgramLog(\u001b[38;5;28mself\u001b[39m.ptr)\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CompileException(log, \u001b[38;5;28mself\u001b[39m.src, \u001b[38;5;28mself\u001b[39m.name, options,\n\u001b[32m    751\u001b[39m                            \u001b[33m'\u001b[39m\u001b[33mnvrtc\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runtime.is_hip \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mhiprtc\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mCompileException\u001b[39m: In file included from /tmp/comgr-9b34e6/input/tmp/tmpqr2ikmde/69c23a85c53435a76e586b8bcb294b7e7120df4e.hsaco.cu:2:\nIn file included from /home/aleisley/Documents/mengai/ai231/.venv/lib/python3.12/site-packages/cupy/_core/include/cupy/carray.cuh:40:\n/usr/lib/gcc/x86_64-redhat-linux/15/../../../../include/c++/15/cstddef:52:10: fatal error: 'stddef.h' file not found\n   52 | #include <stddef.h>\n      |          ^~~~~~~~~~\n1 error generated when compiling for gfx1101."
     ]
    }
   ],
   "source": [
    "import cupy\n",
    "# x = cupy.array([1., 2., 3.])\n",
    "y = cupy.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efadf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy: 13.6.0\n",
      "is_hip: True\n"
     ]
    }
   ],
   "source": [
    "print(\"CuPy:\", cupy.__version__)\n",
    "print(\"is_hip:\", rt.is_hip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai231",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
